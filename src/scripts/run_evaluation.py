#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import os
import argparse
import json
import yaml
from dotenv import load_dotenv

load_dotenv()
# --- Import c√°c l·ªõp/h√†m th·ª±c t·∫ø ---
try:
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

    os.environ["HF_HOME"] = os.getenv("HF_HOME")

    from src.evaluators.score_evaluator import ScoreEvaluator
    from src.evaluators.aesthetic import AestheticEvaluator
    from src.evaluators.siglip import Siglip
    from src.evaluators.vqa import VQAEvaluator
    from src.generators.stable_diffusion_v2 import StableDiffusionV2
    from src.generators.sdxl_turbo import StableDiffusionXL_Turbo
    from src.generators.sdxl_vetor import SDXL_Vector
    from src.data.data_loader import Data  # L·ªõp x·ª≠ l√Ω data
    from src.strategies.build_prompt.categorized_prompt_strategy import (
        CategorizedPromptStrategy,
    )
    from src.strategies.similarity_reward.captioning import CaptionStrategy
    from src.strategies.similarity_reward.clip_similarity import ClipSimilarityStrategy
    from src.strategies.similarity_reward.siglip_similarity import (
        SIGLIPSimilarityStrategy,
    )

    # Import ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu th√¥
    from configs.configs import RAW_DATA_DIR, YAML_CONFIG_FILE

    TRAIN_DATA_PATH = os.path.join(RAW_DATA_DIR, "drawing-with-llms/train.csv")
    QUESTION_DATA_PATH = os.path.join(
        RAW_DATA_DIR, "drawing-with-llms/questions.parquet"
    )
    print(f"--- Using Train Data: {TRAIN_DATA_PATH} ---")
    print(f"--- Using Question Data: {QUESTION_DATA_PATH} ---")

except ImportError as e:
    print(f"L·ªói import: {e}")
    print("Ki·ªÉm tra l·∫°i c·∫•u tr√∫c th∆∞ m·ª•c, PYTHONPATH v√† c√°c file __init__.py.")
    sys.exit(1)
except FileNotFoundError as e:
    print(f"L·ªói kh√¥ng t√¨m th·∫•y file/th∆∞ m·ª•c khi import ho·∫∑c ƒë·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n: {e}")
    sys.exit(1)


def load_config_from_yaml(version_name: str) -> dict:
    """T·∫£i c·∫•u h√¨nh cho m·ªôt version c·ª• th·ªÉ t·ª´ file YAML."""
    if not os.path.exists(YAML_CONFIG_FILE):
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file c·∫•u h√¨nh YAML t·∫°i '{YAML_CONFIG_FILE}'")
        sys.exit(1)
    try:
        with open(YAML_CONFIG_FILE, "r") as f:
            all_configs = yaml.safe_load(f)
    except yaml.YAMLError as e:
        print(f"L·ªói khi ƒë·ªçc file YAML '{YAML_CONFIG_FILE}': {e}")
        sys.exit(1)
    except Exception as e:
        print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi m·ªü file YAML: {e}")
        sys.exit(1)

    if not isinstance(all_configs, dict) or version_name not in all_configs:
        print(
            f"L·ªói: Kh√¥ng t√¨m th·∫•y key version '{version_name}' trong file '{YAML_CONFIG_FILE}'"
        )
        print(
            f"C√°c version c√≥ s·∫µn: {list(all_configs.keys()) if isinstance(all_configs, dict) else 'Kh√¥ng c√≥'}"
        )
        sys.exit(1)

    print(f"--- ƒê√£ t·∫£i c·∫•u h√¨nh cho version: '{version_name}' t·ª´ YAML ---")
    return all_configs[version_name]


def main():
    parser = argparse.ArgumentParser(
        description="Ch·∫°y ƒë√°nh gi√° ·∫£nh t·ª´ config/versions.yaml.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--version",
        type=str,
        required=True,
        help="T√™n version c·∫•u h√¨nh trong versions.yaml.",
    )
    # --- Tham s·ªë ghi ƒë√® c·∫•p cao ---
    # ... (gi·ªØ nguy√™n c√°c args prefix, suffix, neg_prompt, height, width, steps, scale, compress, k, attempts, seed, verbose) ...
    parser.add_argument("--prefix_prompt", type=str, default=None)
    parser.add_argument("--suffix_prompt", type=str, default=None)
    parser.add_argument("--negative_prompt", type=str, default=None)
    parser.add_argument("--height", type=int, default=None)
    parser.add_argument("--width", type=int, default=None)
    parser.add_argument("--num_inference_steps", type=int, default=None)
    parser.add_argument("--guidance_scale", type=float, default=None)
    parser.add_argument(
        "--use_image_compression", action=argparse.BooleanOptionalAction, default=None
    )
    parser.add_argument(
        "--use_prompt_builder", action=argparse.BooleanOptionalAction, default=None
    )
    # <<<--- Th√™m Argument ch·ªçn Similarity/Reward Strategy ---<<<
    parser.add_argument(
        "--similarity_strategy",
        type=str,
        default="clip",  # M·∫∑c ƒë·ªãnh d√πng CLIP
        choices=["clip", "siglip", "caption"],
        help="Chi·∫øn l∆∞·ª£c t√≠nh ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng/th∆∞·ªüng ('clip' ho·∫∑c 'siglip').",
    )
    # >>>-------------------------------------------------->>>

    parser.add_argument("--k", type=int, default=None)
    parser.add_argument("--num_attempts", type=int, default=None)
    parser.add_argument("--random_seed", type=int, default=None)
    parser.add_argument(
        "--verbose", action=argparse.BooleanOptionalAction, default=None
    )
    parser.add_argument("--output_version_name", type=str, default=None)
    # --- Th√™m args ƒë·ªÉ override method v√† model ---
    parser.add_argument(
        "--method", type=str, default=None, help="Ghi ƒë√® t√™n 'method' trong YAML."
    )
    parser.add_argument(
        "--model", type=str, default=None, choices=["StableDiffusionV2", "SDXL-Turbo", "SDXL-Vector"],help="Ghi ƒë√® t√™n 'model' trong YAML."
    )

    # --- Tham s·ªë ghi ƒë√® SVG config (nh∆∞ c≈©) ---
    parser.add_argument("--svg_num_colors", type=int, default=None)
    # ... (gi·ªØ nguy√™n c√°c args svg_max_bytes, svg_resize, svg_target_w/h, svg_adaptive_fill) ...
    parser.add_argument("--svg_max_bytes", type=int, default=None)
    parser.add_argument(
        "--svg_resize", action=argparse.BooleanOptionalAction, default=None
    )
    parser.add_argument("--svg_target_w", type=int, default=None)
    parser.add_argument("--svg_target_h", type=int, default=None)
    parser.add_argument(
        "--svg_adaptive_fill", action=argparse.BooleanOptionalAction, default=None
    )

    # --- Tham s·ªë output t·ªïng h·ª£p ---
    parser.add_argument(
        "--output_json",
        type=str,
        default=None,
        help="ƒê∆∞·ªùng d·∫´n file JSON ƒë·ªÉ l∆∞u t·∫•t c·∫£ k·∫øt qu·∫£.",
    )

    # --- Load YAML v√† Parse Args ---
    known_args, _ = parser.parse_known_args()
    yaml_params = load_config_from_yaml(known_args.version)
    # id_prompt v√† base_bitmap2svg_config s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω trong v√≤ng l·∫∑p n·∫øu c√≥
    base_bitmap2svg_config = yaml_params.get(
        "bitmap2svg_config", {}
    )  # L·∫•y ho·∫∑c d√πng dict r·ªóng n·∫øu thi·∫øu

    # --- ƒê·∫∑t YAML l√†m defaults ---
    yaml_defaults = {
        k: v
        for k, v in yaml_params.items()
        if hasattr(parser, "get_default")
        and hasattr(parser.get_default(k), "__class__")
    }
    parser.set_defaults(**yaml_defaults)
    args = parser.parse_args()

    # --- Kh·ªüi t·∫°o Dependencies v√† ScoreEvaluator (nh∆∞ c≈©) ---
    print("--- Kh·ªüi t·∫°o Dependencies Th·ª±c T·∫ø ---")
    try:
        vqa_evaluator = VQAEvaluator()
        aesthetic_evaluator = AestheticEvaluator()

        if args.model == "StableDiffusionV2":
            print("   Use Stable Diffusion v2")
            generator = StableDiffusionV2()
        elif args.model == "SDXL-Turbo":
            print("   Use Stable Diffusion XL Turbo")
            generator = StableDiffusionXL_Turbo()
        elif args.model == "SDXL-Vector":
            print("   Use Stable Diffusion XL Vector")
            generator = SDXL_Vector()

        data = Data(TRAIN_DATA_PATH, QUESTION_DATA_PATH)
        prompt_builder = CategorizedPromptStrategy()

        # <<<--- Kh·ªüi t·∫°o Similarity/Reward Strategy ƒë∆∞·ª£c ch·ªçn ---<<<
        if args.similarity_strategy == "clip":
            similarity_reward_strategy = ClipSimilarityStrategy(
                aesthetic_evaluator=aesthetic_evaluator
            )
        elif args.similarity_strategy == "caption":
            similarity_reward_strategy = CaptionStrategy(vqa_evaluator=vqa_evaluator)
        elif args.similarity_strategy == "siglip":
            similarity_reward_strategy = SIGLIPSimilarityStrategy(Siglip())
        else:
            print(
                f"L·ªói: Similarity strategy '{args.similarity_strategy}' kh√¥ng h·ª£p l·ªá."
            )
            sys.exit(1)
        print(
            f"--- S·ª≠ d·ª•ng Similarity/Reward Strategy: {type(similarity_reward_strategy).__name__} ---"
        )
        # >>>------------------------------------------------------>>>

    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o dependencies: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
    print("--- Dependencies Initialized ---")
    print("--- Kh·ªüi t·∫°o ScoreEvaluator ---")
    try:
        evaluator = ScoreEvaluator(
            vqa_evaluator,
            aesthetic_evaluator,
            generator,
            data,
            prompt_builder,
            similarity_reward_strategy,
        )
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o ScoreEvaluator: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
    print("--- ScoreEvaluator Initialized ---")

    # --- L·∫•y d·ªØ li·ªáu train ---
    print("--- L·∫•y d·ªØ li·ªáu train t·ª´ Data object ---")
    try:
        train_df = data.get_train_csv()
        id_column_name = "id"  # Ho·∫∑c 'id_prompt', 'row_id'... -> S·ª≠a n·∫øu c·∫ßn
        if id_column_name not in train_df.columns:
            print(f"L·ªói: Kh√¥ng t√¨m th·∫•y c·ªôt ID '{id_column_name}'.")
            sys.exit(1)
        print(f"--- T√¨m th·∫•y {len(train_df)} prompts trong train data ---")
    except Exception as e:
        print(f"L·ªói khi g·ªçi data.get_train_csv(): {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    # --- Chu·∫©n b·ªã c√°c tham s·ªë c·ªë ƒë·ªãnh v√† x·ª≠ l√Ω override 1 l·∫ßn ---
    output_version_name = (
        args.output_version_name
        if args.output_version_name
        else yaml_params.get("version_description", args.version)
    )
    final_verbose = (
        args.verbose if args.verbose is not None else yaml_params.get("verbose", False)
    )
    final_use_prompt_builder = (
        args.use_prompt_builder
        if args.use_prompt_builder is not None
        else yaml_params.get("use_prompt_builder", False)
    )
    final_use_compression = (
        args.use_image_compression
        if args.use_image_compression is not None
        else yaml_params.get("use_image_compression", False)
    )
    final_k = args.k if args.k is not None else yaml_params.get("k")
    if final_use_compression and final_k is None:
        print("Warning: compress=true nh∆∞ng k kh√¥ng x√°c ƒë·ªãnh. D√πng default k=8.")
        final_k = 8
    final_method = (
        args.method
        if args.method is not None
        else yaml_params.get("method", "UnknownMethod")
    )  # L·∫•y method
    final_model = (
        args.model
        if args.model is not None
        else yaml_params.get("model", "UnknownModel")
    )  # L·∫•y model

    # X·ª≠ l√Ω override cho SVG config
    final_bitmap2svg_config = base_bitmap2svg_config.copy()
    if args.svg_num_colors is not None:
        final_bitmap2svg_config["num_colors"] = args.svg_num_colors
    # ... (x·ª≠ l√Ω c√°c override svg kh√°c nh∆∞ c≈©) ...
    if args.svg_max_bytes is not None:
        final_bitmap2svg_config["max_size_bytes"] = args.svg_max_bytes
    if args.svg_resize is not None:
        final_bitmap2svg_config["resize"] = args.svg_resize
    target_w, target_h = args.svg_target_w, args.svg_target_h
    if target_w is not None or target_h is not None:
        current_target_size = tuple(
            base_bitmap2svg_config.get("target_size", [384, 384])
        )
        new_w = target_w if target_w is not None else current_target_size[0]
        new_h = target_h if target_h is not None else current_target_size[1]
        final_bitmap2svg_config["target_size"] = [new_w, new_h]
    if args.svg_adaptive_fill is not None:
        final_bitmap2svg_config["adaptive_fill"] = args.svg_adaptive_fill
    if "num_colors" not in final_bitmap2svg_config:
        print(
            "Warning: 'num_colors' kh√¥ng c√≥ trong bitmap2svg_config. D√πng default=12."
        )
        final_bitmap2svg_config["num_colors"] = 12

    base_evaluation_params = {
        "prefix_prompt": args.prefix_prompt,
        "suffix_prompt": args.suffix_prompt,
        "negative_prompt": args.negative_prompt,
        "width": args.width,
        "height": args.height,
        "num_inference_steps": args.num_inference_steps,
        "guidance_scale": args.guidance_scale,
        "use_image_compression": final_use_compression,
        "use_prompt_builder": final_use_prompt_builder,
        "compression_k": final_k,
        "bitmap2svg_config": final_bitmap2svg_config,
        "version": output_version_name,  # D√πng cho th∆∞ m·ª•c output b√™n trong ScoreEvaluator
        "num_attempts": args.num_attempts if args.num_attempts is not None else 1,
        "verbose": final_verbose,
        "random_seed": args.random_seed if args.random_seed is not None else 42,
    }
    # Ki·ªÉm tra None cho c√°c gi√° tr·ªã b·∫Øt bu·ªôc
    required_keys = [
        "prefix_prompt",
        "suffix_prompt",
        "negative_prompt",
        "height",
        "width",
        "num_inference_steps",
        "guidance_scale",
        "use_image_compression",
        "use_prompt_builder",
        "num_attempts",
        "random_seed",
    ]
    missing_keys = [k for k in required_keys if base_evaluation_params.get(k) is None]
    if missing_keys:
        print(f"L·ªói: C√°c tham s·ªë c∆° b·∫£n sau b·ªã thi·∫øu: {missing_keys}")
        sys.exit(1)

    # --- V√≤ng l·∫∑p x·ª≠ l√Ω ---
    all_results = []
    success_count = 0
    fail_count = 0
    total_prompts = len(train_df)

    print(
        f"\n--- B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {total_prompts} prompts v·ªõi c·∫•u h√¨nh version '{args.version}' ---"
    )
    print(f"--- Method: {final_method}, Model: {final_model} ---")
    print("-" * 30)

    for index, row in train_df.iterrows():
        current_id_prompt = row[id_column_name]
        print(
            f"\n--- [{index + 1}/{total_prompts}] Processing ID: {current_id_prompt} ---"
        )

        current_evaluation_params = base_evaluation_params.copy()
        current_evaluation_params["id_prompt"] = current_id_prompt

        try:
            # G·ªçi h√†m generate_and_evaluate (kh√¥ng c·∫ßn truy·ªÅn method, model v√†o ƒë√¢y)
            result_core = evaluator.generate_and_evaluate(**current_evaluation_params)

            # !!! Th√™m method v√† model v√†o k·∫øt qu·∫£ TR∆Ø·ªöC KHI l∆∞u !!!
            # T·∫°o b·∫£n sao ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng l·∫ßn l·∫∑p sau n·∫øu result_core l√† mutable reference
            result_final = result_core.copy()
            result_final["method"] = final_method
            result_final["model"] = final_model

            # Th√™m k·∫øt qu·∫£ ƒë√£ b·ªï sung metadata
            all_results.append(result_final)
            success_count += 1
            print(f"--- Ho√†n th√†nh ID: {current_id_prompt} ---")
            if final_verbose:
                print(json.dumps(result_final, indent=2))

        except Exception as e:
            fail_count += 1
            print(f"üö® L·ªói khi x·ª≠ l√Ω ID {current_id_prompt}: {e} ---")
            error_result = {
                "id_desc": current_id_prompt,  # ƒê·ªïi t√™n key cho kh·ªõp v·ªõi k·∫øt qu·∫£ th√†nh c√¥ng n·∫øu mu·ªën
                "status": "FAILED",
                "error": str(e),
                "method": final_method,
                "model": final_model,  # Th√™m metadata v√†o c·∫£ l·ªói
                "config_version": args.version,
                "output_version": output_version_name,
            }
            all_results.append(error_result)

    # --- T·ªïng k·∫øt v√† L∆∞u k·∫øt qu·∫£ ---
    print("\n" + "=" * 50)
    print("--- X·ª≠ l√Ω ho√†n t·∫•t ---")
    print(
        f"T·ªïng s·ªë prompts: {total_prompts}, Th√†nh c√¥ng: {success_count}, Th·∫•t b·∫°i: {fail_count}"
    )
    print("=" * 50)

    if args.output_json:
        output_file_path = args.output_json
        output_dir = os.path.dirname(output_file_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        try:
            with open(output_file_path, "w", encoding="utf-8") as f:
                json.dump(all_results, f, indent=4, ensure_ascii=False)
            print(f"--- ƒê√£ l∆∞u t·ªïng h·ª£p k·∫øt qu·∫£ v√†o: {output_file_path} ---")
        except Exception as e:
            print(f"L·ªói khi l∆∞u file k·∫øt qu·∫£ JSON: {e}")
    else:
        print("--- K·∫øt qu·∫£ t·ªïng h·ª£p kh√¥ng ƒë∆∞·ª£c l∆∞u v√†o file (d√πng --output_json). ---")


if __name__ == "__main__":
    main()
